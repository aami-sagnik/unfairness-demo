# unfairness-demo
A demo of how unfairness can be propagated by ML models.
I used the COMPASS dataset on [kaggle](https://www.kaggle.com/datasets/danofer/compass) to train a model (a Random Forest Regressor) to predict the decile score for a candidate. Ethnicity was one of the parameters used for training the model. My intent is to showcase how choosing an unfair model for decision-making in a consequential scenario can lead to unfair outcomes. 
